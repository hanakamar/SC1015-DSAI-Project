{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "630d1639-1546-4424-a580-1f09b7917164",
   "metadata": {},
   "source": [
    "# SC1015 Mini Project: Social Media & Fashion\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6571b-fa8f-4b20-a3f8-62578161ff48",
   "metadata": {},
   "source": [
    "School of Computer Science and Engineering  \n",
    "Nanyang Technological University  \n",
    "Group: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de751281-9caf-4a6a-b1a3-ab4d76db0aaf",
   "metadata": {},
   "source": [
    "## Members:\n",
    "> 1. Balasubramanian Roopashanthoshini (U2323844J)\n",
    "> 2. Dhanapalan Swaminathan Sudhsishna Janavi (U2320155K)\n",
    "> 3. Kamarudeen Hana Fathima (U2323533G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63b9193-c653-4cb1-bd6e-65d3af64219d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0dc298-8474-4443-adbd-e4b62049ab83",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "> 1. Data Preparation and Cleaning\n",
    "> 2. Exploratory Data Analysis\n",
    "> 3. Anomaly detection\n",
    "> 4. Insights from relationships in raw dataset\n",
    "> 5. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93247d-688a-4cfe-9973-b1e6e933b12c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39346f0-3f84-4914-8659-e068c96fd3b4",
   "metadata": {},
   "source": [
    "## Problem Definition\n",
    "> Our aim is to use data collated from instagram posts from fashion influencers characterized by their features, such as user details, image features and features of the fashion item to accurately determine what metrics can effectively predict post popularity and subsequently, what metrics are most valuable to fashion brands looking to advertise on Social Media and leverage influencer marketing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d50300-909f-40eb-af41-029bcd0f4299",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54c0fd4-d2ab-4061-821c-2349c3a3b949",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "> Ha, Yu-i; Kwon, Sejeong; Cha, Meeyoung; Joo, Jungseock, 2017, \"Fashion conversation data on Instagram\", https://doi.org/10.7910/DVN/K7AW6F, Harvard Dataverse, V1, UNF:6:a/JWNHEGsJreZVqhBkLhgg== [fileUNF]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ca9268-620a-43ba-bf0d-d7a9674fd781",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5754dde8-0936-4705-a4d2-3ac6b3199589",
   "metadata": {},
   "source": [
    "## 1. Data Preparation and Cleaning\n",
    "In this file, we prepped and cleaned our dataset to work with it in the subsequent files. This involved:\n",
    "> - Sanity chekcs for duplicate and missing values\n",
    "> - Isolating numeric variables which we needed to work with in our dataset\n",
    "> - Segregating the entire dataset into 4 sections; each uniqe brand category for deeper, specific exploration into each\n",
    "> - Removing outliers by using a personalized function\n",
    "> - Conversion of each dataframe to sepaarte CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8dd75b-4d00-47b1-af6f-1dfbd7f25b63",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "In this file, we conducted a prelimiary exploration into our dataset to further determine which direction to take, which variables have correlations worth exploring & visualizing our conclusions. We accomplished this by:\n",
    "> - Univariate exploration of our response variable - 'Likes' (Number of likes on a post)\n",
    "> - Correlation charts with values on what variables had strongest correlations with Likes for our original and cleaned datasets\n",
    "> - Visualizing top variables with correlations for each brand category\n",
    "\n",
    "We concluded that Likes was an extremely narrow variable ranging from 10-50 but with lots of outliers that may skew the dataset. Hence when we visualized the correlations for both original and cleaned dataset - we found that correlations were much stronger, and distinct for our original dataset compared to that of the cleaned, which led us to discard the cleaned dataset and focus on the original one. We further visualized top variables that correlated well with Likes - Followers & Comments - and we found they too were narrow variables accorss the board for each brand category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20abe97c-71ed-4bca-bbbf-06a28ea2ce87",
   "metadata": {},
   "source": [
    "## 3. Anomaly Detection\n",
    "In this file, we try outlier removal by anomaly detection using the isolating forests method as a fail-safe to ensure using the original dataset is more optimal than the cleaned dataset. This was executed by:\n",
    "> - Creating a cleaned dataset by the isolating forests technique\n",
    "> - Identifying outliers produced by this method\n",
    "> - Computing correlations to likes in each brand category with this new cleaned dataset\n",
    "> - Identifying top 4 variables with strongest correlations\n",
    "\n",
    "By producing a cleaned dataset and computing correlations, we've compiled 3 datasets - the raw one and two cleaned (using IQR and isolated forests technique) and we've found correlations varied significantly accross the three and that the removal of outliers may have been responsibly for the decrease in the strength of correlations between followers and likes. Our decision to stick with the original dataset was due to the consistent top correlations with variables as well as the fact that the cleaned dataset missed extremes that may explain data behaviours for user engagement which may be key to understanding which metric is most valuable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a9d2eb-8155-40aa-9845-7596677e3704",
   "metadata": {},
   "source": [
    "## 4. Insights from relationships in raw dataset\n",
    "In this file, we conducted bivariate exploration into the top two variables - Followers & Comments - with Likes for each brand category and executed multiple kind of regression models for further analysis. This consisted of:\n",
    "\n",
    "> - Bivariate exploration of Likes with Followers & Comments by analyzing correlation statistics\n",
    "> - Multiple linear regression models using Followers & Comments against Likes for each brand category in order to find a reliable model that provides a good predictor for likes\n",
    "> - Ridge & Lasso regression models to further improve on regression analyses for the 2 variables in each brand category\n",
    "\n",
    "By constructing bivariate explorations, we learned that Followers had a much stronger correlation to Likes than Comments did, but for most brand categories, correlations were still strong for both variables, proving their worth as reliable predictors for Likes and overall, to predict post popularity. Hence we then used multiple linear regression models for each brand category to expound on this and Designer stuck out as the R^2 values were negative implying the dataset was a poor fit for the linear regression model. For the other, R^2 values explained a subtantial portion of the dataset. In order to improve these values, we executed lasso & ridge regression models which yielded similar but mostly higher values. However, from all the linear regression models, we found that Comments was a better predictor than Followers, which indicated stronger correlations did not necessarily translate to being better predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c61bb1-231b-453a-8e9f-ec65574d85ac",
   "metadata": {},
   "source": [
    "## 5. Clustering\n",
    "In this file, we executed a Clustering data analysis based on a K-means algorithm in order to further understad the insights we gained from our previous bivariate analysis and linear regression models. This consisted of:\n",
    "> - Using Elbow method to determine number of clusters required\n",
    "> - Clustering based on brand category into 2 clusters\n",
    "> - Identifying distinctive features of clusters\n",
    "\n",
    "Clustering the data under four brand categories helped us realise that even though comments have lower correlations with likes in comparison to followers, both comments and likes aligned on the same track when seen from the perspective of \"user-engagement\", whereas the number of followers highly indicated the \"user-reach\". As observed, whenever a cluster is found to have a higher number of followers, it was not necessary to see a high number of likes in that cluster. However, whenever the number of likes were high, it was seen that the number of comments received by the posts in that cluster were also high in most of the clusters under all the four brand categories. This suggested the use of comments as a better predictor when studying the variable likes in comparison to followers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa858f63-b08f-4193-b50a-9ddac4feff47",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed2de0-fc90-40e1-9af7-b636c77ff5cf",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "> In a nutshell, our data analysis has helped identify user engagement, particularly with respect to comments, as a more potential predictor post popularity compared to mere follower count. Regression and cluster analysis aided in proving the fact that active user interaction and engagement strongly correlates with likes. This also helped us reach the conclusion that it is indeed vital for fashion brands to come up with effective strategies that increase user engagement and not just broaden its reach. Despite the fact that this study was centered around Instagram posts and may overlook some external factors, our data analysis has helped conclude that user-engagement is a primary factor for social media success with the use of our robust data science concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9734fba5-e5ba-4f6d-860a-7a7aa3751378",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1002d469-5ec7-4233-acbd-2cfd4dce28f6",
   "metadata": {},
   "source": [
    "## Contributions\n",
    "> - Hana - Insights into relationships, Video, part of EDA \n",
    "> - Sudhishna - Clustering, Anomaly Detection part of EDA \n",
    "> - Roopa - Data preparation & cleaning, Sliding, part of EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508d661-2c1b-437a-a5e3-76e4a9b329aa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ef38b5-2f98-485f-b13c-d1e55433fc14",
   "metadata": {},
   "source": [
    "## Data analysis tools\n",
    "> - Feature engineering (Multiple linear regression model, Lasso & Ridge regression model)\n",
    "> - Correlation relationships\n",
    "> - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4434256-4bab-489c-a1ac-9c7897f978c7",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cd2303-febd-48db-9ea4-7ed2d5b8f173",
   "metadata": {},
   "source": [
    "## Our learnings\n",
    "> - Clustering our datasets\n",
    "> - Aggregating unique features from variables (Groupby)\n",
    "> - Ridge Regression Model\n",
    "> - Lasso Regression Model\n",
    "> - Multiple Linear Regresssion model\n",
    "> - Anomaly detection using Isolation Forests\n",
    "> - Warnings library\n",
    "> - Github\n",
    "> - Determine viability of dataset based on outlier removal\n",
    "> - Converting parts of the dataset into csv files to be used later on instead of importing the entire dataset again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c5a31d-2694-4d43-8a72-5dc0ce509893",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c345d6-0a50-490f-8e75-380b319d808b",
   "metadata": {},
   "source": [
    "## References\n",
    "> 1. ChatGPT prompts: \"How to reduce overfitting on linear regression models\", \"Understanding clustering\", \"Limitations of outlier removal and alternative methods to remove outliers\"\n",
    "> 2. https://www.geeksforgeeks.org/clustering-in-machine-learning/\n",
    "> 3. https://scikit-learn.org/stable/modules/clustering.html\n",
    "> 4. https://www.analyticsvidhya.com/blog/2021/09/lasso-and-ridge-regularization-a-rescuer-from-overfitting/\n",
    "> 5. https://www.analyticsvidhya.com/blog/2021/07/anomaly-detection-using-isolation-forest-a-complete-guide/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
